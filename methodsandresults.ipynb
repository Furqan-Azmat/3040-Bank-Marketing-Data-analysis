{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "949faa06",
   "metadata": {},
   "source": [
    "## Question 1: Optimal Call Count Analysis\n",
    "\n",
    "### Research Question\n",
    "On average, how many calls does it take for a client to say \"yes\" to the term deposit subscription? At what point does calling again result in a negative outcome?\n",
    "\n",
    "### Methods\n",
    "\n",
    "#### 1. Exploratory Data Analysis\n",
    "- **Conversion Rate Analysis**: Calculated conversion rates by number of calls to identify patterns in client responses\n",
    "- **Peak Detection**: Identified the optimal number of calls where conversion rate is highest\n",
    "- **Threshold Analysis**: Determined points where conversion rates drop significantly (below 50% of peak and below 1%)\n",
    "\n",
    "#### 2. Logistic Regression Model\n",
    "**Why this method?**\n",
    "- Logistic regression is ideal for binary classification (yes/no subscription)\n",
    "- Provides probability estimates for subscription likelihood based on call count\n",
    "- Class balancing (`class_weight='balanced'`) was applied to handle the imbalanced dataset where \"no\" responses significantly outnumber \"yes\" responses\n",
    "- Simple, interpretable model that directly relates call count to conversion probability\n",
    "\n",
    "**Implementation:**\n",
    "- Feature: `campaign` (number of calls during this campaign)\n",
    "- Target: Binary subscription outcome (yes=1, no=0)\n",
    "- 80/20 train-test split with stratification\n",
    "- Balanced class weights to prevent bias toward majority class\n",
    "\n",
    "#### 3. Polynomial Regression (Degree 3)\n",
    "**Why this method?**\n",
    "- Captures non-linear relationship between call count and conversion rate\n",
    "- Models the rise and fall pattern observed in the data (peak at early calls, then decline)\n",
    "- Degree 3 polynomial allows for an initial increase, peak, and subsequent decline\n",
    "\n",
    "**Implementation:**\n",
    "- Aggregated data by call count to compute average conversion rates\n",
    "- Applied polynomial features transformation\n",
    "- Fitted linear regression on polynomial features to model the trend\n",
    "\n",
    "### Results\n",
    "\n",
    "#### Key Findings:\n",
    "1. **Peak Conversion Rate**: **13.04%** at **1 call**\n",
    "   - This indicates that the first contact is most effective\n",
    "   - Early engagement is crucial for conversion\n",
    "\n",
    "2. **Average Calls for Successful Conversions**: **2.05 calls** (median: 2 calls)\n",
    "   - Clients who subscribe typically require only a few contacts\n",
    "   - Median is lower, suggesting most successful conversions happen quickly\n",
    "\n",
    "3. **Diminishing Returns**: \n",
    "   - Conversion rate drops below 50% of peak after **7 calls** (6.04%)\n",
    "   - Conversion rate falls below 1% after **16 calls**\n",
    "   - Calling beyond this point yields minimal results\n",
    "\n",
    "4. **Model Performance**:\n",
    "   - Logistic Regression Test AUC: **0.5487**\n",
    "   - Logistic Regression Test Recall: **0.7594** (76% of actual \"yes\" clients captured)\n",
    "   - Polynomial model R²: **varies by implementation** (captures trend well)\n",
    "\n",
    "- **First impressions matter**: The highest conversion rate occurs on the first call (13.04%), suggesting that well-targeted initial contacts are critical\n",
    "- **Stop calling after diminishing returns**: Beyond 7 calls, conversion drops below 50% of peak (6.04%). After 16 calls, conversion rate falls below 1%\n",
    "- **Stop calling after diminishing returns**: Beyond 3-4 calls, the probability of success drops significantly. Continuing to call after 7-8 attempts is counterproductive\n",
    "- **Strategic recommendation**: Prioritize quality of first contact over quantity of follow-ups. Hard stop at 16 calls maximum\n",
    "- **Before vs After Peak**: Clients contacted ≤1 time have 13.04% conversion vs 9.94% for >1 call (3.10 percentage point difference)\n",
    "\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e0fcb4",
   "metadata": {},
   "source": [
    "## Question 2: High-Response vs Low-Response Classification\n",
    "\n",
    "### Research Question\n",
    "Can we classify clients into \"high-response\" and \"low-response\" groups to optimize call targeting and reduce campaign costs?\n",
    "\n",
    "### Methods\n",
    "\n",
    "#### 1. Logistic Regression with One-Hot Encoding\n",
    "**Why this method?**\n",
    "- Logistic regression is a proven baseline for binary classification tasks\n",
    "- Handles mixed data types (categorical and numerical) through preprocessing\n",
    "- Provides interpretable probability scores for client response likelihood\n",
    "- Balanced class weights (`class_weight='balanced'`) address the severe class imbalance (~11% yes, 89% no)\n",
    "\n",
    "**Implementation:**\n",
    "- **Preprocessing Pipeline**:\n",
    "  - Categorical features: One-Hot Encoding (`OneHotEncoder` with `handle_unknown='ignore'`)\n",
    "  - Numerical features: Passed through without transformation\n",
    "  - **Critical**: Removed `duration` feature to prevent data leakage (duration is only known after the call ends)\n",
    "- **Model**: Logistic Regression with balanced class weights and max 500 iterations\n",
    "- **Split**: 80/20 stratified train-test split to maintain class proportions\n",
    "\n",
    "#### 2. Comparative Models\n",
    "To validate the logistic regression approach, additional models were tested:\n",
    "- **K-Nearest Neighbors (KNN)**: Non-parametric, instance-based learning\n",
    "- **Decision Tree**: Non-linear, rule-based classifier\n",
    "- **Gaussian Naive Bayes**: Probabilistic classifier assuming feature independence\n",
    "\n",
    "### Results\n",
    "\n",
    "#### Logistic Regression Performance:\n",
    "- **ROC-AUC**: **0.798** (strong discriminative ability)\n",
    "- **Precision (high-response)**: **0.35** (35% of predicted \"yes\" are actual \"yes\")\n",
    "- **Recall (high-response)**: **0.65** (captures 65% of all actual \"yes\" clients)\n",
    "- **F1-Score (high-response)**: **0.46** (harmonic mean of precision and recall)\n",
    "- **Overall Accuracy**: **82%**\n",
    "\n",
    "#### Model Comparison:\n",
    "- **Logistic Regression**: Best overall balance, highest AUC\n",
    "- **Decision Tree**: Good recall but lower precision\n",
    "- **KNN**: Moderate performance, computationally expensive\n",
    "- **Naive Bayes**: Fast but lower performance due to feature correlation\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "#### Business Impact:\n",
    "1. **High Recall is Critical**: In marketing campaigns, missing a potential subscriber (false negative) is more costly than contacting a non-subscriber (false positive)\n",
    "   - Recall of **64-70%** means we capture most potential subscribers\n",
    "   - This maximizes revenue opportunities\n",
    "2. **Precision Trade-off**: Precision of **35%** means:\n",
    "   - If we call 100 \"predicted high-response\" clients, 35 will subscribe\n",
    "   - This is **3.2x better than random calling** (baseline ~11% conversion rate)\n",
    "   - This is **3.3x better than random calling** (baseline ~11% conversion rate)\n",
    "   - Significant cost savings by focusing on high-probability clients\n",
    "\n",
    "   - By targeting top clients (by probability score), we can:\n",
    "     - Reduce call volume significantly\n",
    "     - Maintain 65% of potential revenue (recall)\n",
    "     - Maintain 64-70% of potential revenue\n",
    "     - Focus agent time on quality interactions\n",
    "\n",
    "4. **ROC-AUC of 0.798**: Indicates strong ability to rank clients by response probability\n",
    "   - Model can effectively distinguish between high and low response clients\n",
    "   - Threshold tuning allows for flexible optimization based on business priorities\n",
    "\n",
    "#### Strategic Recommendations:\n",
    "- **Implement tiered calling strategy**: Prioritize clients with highest predicted probability\n",
    "- **Allocate resources efficiently**: Focus experienced agents on borderline cases\n",
    "- **Monitor and update**: Continuously retrain model as new campaign data becomes available\n",
    "- **A/B testing**: Validate model-driven targeting against traditional approaches\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878a8174",
   "metadata": {},
   "source": [
    "## Question 3: Feature Combination for Prediction\n",
    "\n",
    "### Research Question\n",
    "Which combination of client and campaign features most strongly predicts whether a client subscribes to a term deposit?\n",
    "\n",
    "### Methods\n",
    "\n",
    "#### 1. Automated Feature Selection Techniques\n",
    "**Why multiple methods?**\n",
    "- Different techniques capture different aspects of feature importance\n",
    "- Consensus across methods identifies truly important features\n",
    "- Reduces risk of overfitting to a single selection method\n",
    "\n",
    "**Techniques Applied:**\n",
    "\n",
    "##### a. Correlation Analysis (Numeric Features)\n",
    "- Measures linear relationships between numeric features and target\n",
    "- Fast, interpretable, but limited to linear relationships\n",
    "\n",
    "##### b. Mutual Information\n",
    "- Captures both linear and non-linear dependencies\n",
    "- Information-theoretic measure of feature-target relationship\n",
    "- Applied to one-hot encoded features\n",
    "\n",
    "##### c. Random Forest Feature Importance\n",
    "- Measures how much each feature contributes to prediction accuracy\n",
    "- Captures complex interactions and non-linear relationships\n",
    "- Ensemble method reduces noise in importance scores\n",
    "\n",
    "##### d. Recursive Feature Elimination (RFE)\n",
    "- Iteratively removes least important features\n",
    "- Considers feature interactions during elimination\n",
    "- Selected top 7 features based on logistic regression\n",
    "\n",
    "##### e. Gradient Boosting Feature Importance\n",
    "- Similar to Random Forest but with boosting (sequential learning)\n",
    "- Often provides different perspective on feature importance\n",
    "\n",
    "##### f. Principal Component Analysis (PCA)\n",
    "- Dimensionality reduction to understand data structure\n",
    "- Visualizes class separability in reduced space\n",
    "\n",
    "#### 2. Final Feature Selection\n",
    "**Selected Top 7 Features:**\n",
    "1. `euribor3m` - Euribor 3 month rate (macroeconomic indicator)\n",
    "2. `age` - Client age\n",
    "3. `campaign` - Number of contacts during this campaign\n",
    "4. `nr.employed` - Number of employees (macroeconomic indicator)\n",
    "5. `pdays` - Days since last contact from previous campaign\n",
    "6. `emp.var.rate` - Employment variation rate (macroeconomic indicator)\n",
    "7. `cons.conf.idx` - Consumer confidence index (macroeconomic indicator)\n",
    "\n",
    "**Why these 7 features?**\n",
    "- Appeared consistently across multiple selection methods\n",
    "- Balance between **macroeconomic context**, **client demographics**, and **campaign history**\n",
    "- **Excludes `duration`** to prevent data leakage (not available before call)\n",
    "- Interpretable and actionable for business decisions\n",
    "\n",
    "#### 3. Model Benchmarking\n",
    "Four models tested with selected features:\n",
    "\n",
    "##### a. Logistic Regression\n",
    "- Linear baseline with balanced class weights\n",
    "- Fast, interpretable\n",
    "\n",
    "##### b. K-Nearest Neighbors (KNN)\n",
    "- Non-parametric, instance-based\n",
    "- k=10 with distance weighting\n",
    "\n",
    "##### c. Decision Tree\n",
    "- Non-linear, rule-based\n",
    "- Controlled depth (max_depth=6) to prevent overfitting\n",
    "- min_samples_leaf=50 for generalization\n",
    "\n",
    "##### d. Gaussian Naive Bayes\n",
    "- Probabilistic baseline\n",
    "- Fast training\n",
    "\n",
    "### Results\n",
    "\n",
    "#### Feature Importance Consensus:\n",
    "**Top Features Across All Methods:**\n",
    "1. **Macroeconomic Indicators** (nr.employed, euribor3m, emp.var.rate):\n",
    "   - Strongest predictors overall\n",
    "   - Reflect economic climate affecting client decisions\n",
    "   - Outside bank's control but critical for targeting timing\n",
    "\n",
    "2. **Campaign History** (pdays, poutcome):\n",
    "   - Previous contact outcomes highly predictive\n",
    "   - pdays=999 (never contacted) is significant feature\n",
    "   - Importance of relationship history\n",
    "\n",
    "3. **Client Demographics** (age, campaign):\n",
    "   - Age shows moderate correlation\n",
    "   - Campaign (call count) important but shows diminishing returns\n",
    "\n",
    "#### Model Performance (Top 7 Features):\n",
    "\n",
    "| Model | AUC | Recall | Precision | Best For |\n",
    "|-------|-----|--------|-----------|----------|\n",
    "| **Decision Tree** | **0.80** | 0.608 | **0.450** | **Best overall AUC & Precision** |\n",
    "| **Logistic Regression** | 0.78 | **0.733** | 0.256 | **Maximizing recall** |\n",
    "| **Gaussian Naive Bayes** | 0.78 | 0.496 | 0.457 | Balanced performance |\n",
    "| **KNN** | 0.72 | 0.332 | 0.434 | Local patterns |\n",
    "\n",
    "#### Key Findings:\n",
    "\n",
    "1. **Best Model for AUC: Decision Tree**\n",
    "   - **AUC: 0.80** (best discriminative power among tested models)\n",
    "   - **Recall: 0.608** (captures 61% of potential subscribers)\n",
    "   - **Precision: 0.450** (45% of predicted \"yes\" are actual \"yes\")\n",
    "   - Provides interpretable rules for business users\n",
    "   - Can be visualized for stakeholder communication\n",
    "\n",
    "2. **Best Model for Recall: Logistic Regression**\n",
    "   - **AUC: 0.78** (strong performance)\n",
    "   - **Recall: 0.733** (captures 73% of potential subscribers - highest)\n",
    "   - **Precision: 0.256** (26% precision - trade-off for high recall)\n",
    "   - Best when goal is to minimize missed opportunities\n",
    "\n",
    "3. **Feature Selection Impact**:\n",
    "   - Using only 7 features achieves **0.72-0.80 AUC** across models\n",
    "   - Demonstrates that selected features capture most predictive information\n",
    "   - Simpler models with fewer features = faster deployment, easier maintenance\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "#### Business Insights:\n",
    "\n",
    "1. **Economic Context Matters Most**:\n",
    "   - Macroeconomic indicators (euribor3m, nr.employed, emp.var.rate) are strongest predictors\n",
    "   - **Strategic implication**: Time campaigns during favorable economic conditions\n",
    "   - Monitor economic indicators to optimize campaign timing\n",
    "   - During recession/high unemployment, expect lower conversion rates\n",
    "\n",
    "2. **Client History is Powerful**:\n",
    "   - Previous campaign outcomes (`poutcome`) highly predictive\n",
    "   - Clients with successful previous contacts are more likely to subscribe again\n",
    "   - **Strategic implication**: Maintain detailed client interaction history\n",
    "   - Prioritize clients with positive previous outcomes\n",
    "\n",
    "3. **Demographics Play Supporting Role**:\n",
    "   - Age and contact frequency matter but less than economic/history factors\n",
    "   - **Strategic implication**: Don't over-segment by demographics alone\n",
    "   - Use demographic features in combination with economic/history data\n",
    "   - Logistic Regression: High recall (73%) but lower precision (26%)\n",
    "   - Decision Tree: Balanced approach (61% recall, 45% precision)\n",
    "   - Gaussian Naive Bayes: Middle ground (50% recall, 46% precision)\n",
    "   - **Strategic implication**: Choose model based on business priority\n",
    "   - Threshold can be tuned based on call capacity and business priorities\n",
    "\n",
    "#### Actionable Recommendations:\n",
    "1. **Deploy Decision Tree model** (best AUC 0.80) or **Logistic Regression** (best recall 0.73) using top 7 features based on business priority\n",
    "1. **Deploy Naive Bayes or Decision Tree model** using top 7 features\n",
    "2. **Score all clients** before campaigns and rank by subscription probability\n",
    "3. **Focus on high-probability clients first**, especially during:\n",
    "   - Favorable economic conditions (low euribor3m, stable employment)\n",
    "4. **Avoid over-contacting**: Combine with Question 1 findings (stop after 16 calls max, optimally after 7 calls)\n",
    "4. **Avoid over-contacting**: Combine with Question 1 findings (stop after 3-4 unsuccessful calls)\n",
    "5. **Monitor model performance** and retrain quarterly with new campaign data\n",
    "6. **A/B test** model-driven approach against current targeting strategy\n",
    "\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a16590",
   "metadata": {},
   "source": [
    "## Overall Conclusions\n",
    "\n",
    "### Integrated Insights:\n",
    "\n",
    "1. **Quality over Quantity**: First contact is most important (13.04% conversion); diminishing returns after 7 calls (drops to 6.04%)\n",
    "2. **Smart Targeting Works**: Classification models achieve 3.2x improvement over random calling (35% vs 11% baseline)\n",
    "3. **Context is King**: Macroeconomic factors are strongest predictors - time campaigns wisely\n",
    "4. **Simple Models Win**: Top 7 features with Decision Tree achieves 0.80 AUC; Logistic Regression achieves 0.78 AUC with 73% recall\n",
    "\n",
    "### Combined Strategy:\n",
    "\n",
    "1. **Pre-Campaign**: Score all clients using Question 3 model (Decision Tree for best AUC 0.80, or Logistic Regression for highest recall 0.73)\n",
    "2. **Targeting**: Call clients in order of predicted probability (Question 2 insights - AUC 0.798)\n",
    "3. **Execution**: Prioritize first contact quality (13.04% peak conversion on call 1)\n",
    "4. **Stop Rule**: Cease calling after 7 calls (50% drop from peak) or maximum 16 calls (below 1% conversion)\n",
    "5. **Timing**: Launch campaigns during favorable economic conditions\n",
    "\n",
    "### Expected Impact:\n",
    "\n",
    "- **Significant reduction** in wasted call volume\n",
    "- **Maintain 61-73%** of potential subscribers (depending on model choice)\n",
    "- **3.2x improvement** in contact efficiency (35% precision vs 11% baseline)\n",
    "- **Significant cost savings** from reduced agent time\n",
    "- **Better customer experience** through reduced unwanted contacts and better targeting\n",
    "\n",
    "---\n",
    "\n",
    "## Technical Summary\n",
    "\n",
    "### Data:\n",
    "- **Dataset**: Bank Marketing Dataset (UCI)\n",
    "- **Size**: ~41,000 records\n",
    "- **Class Balance**: ~11% yes, 89% no (highly imbalanced)\n",
    "- **Split**: 80/20 train-test, stratified\n",
    "- **Critical preprocessing**: Removed `duration` to prevent data leakage\n",
    "\n",
    "### Best Practices Demonstrated:\n",
    "1. **Proper data splitting** with stratification\n",
    "2. **Data leakage prevention** (removed duration)\n",
    "3. **Class imbalance handling** (balanced weights, recall focus)\n",
    "4. **Multiple validation approaches** (train-test, cross-validation)\n",
    "5. **Consensus feature selection** (multiple methods)\n",
    "6. **Model comparison** (multiple algorithms)\n",
    "7. **Business-focused metrics** (recall prioritized over precision)\n",
    "8. **Interpretability** (simple models, feature importance analysis)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
