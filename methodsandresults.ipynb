{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "949faa06",
   "metadata": {},
   "source": [
    "## Question 1: Optimal Call Count Analysis\n",
    "\n",
    "### Research Question\n",
    "On average, how many calls does it take for a client to say \"yes\" to the term deposit subscription? At what point does calling again result in a negative outcome?\n",
    "\n",
    "### Methods\n",
    "\n",
    "#### 1. Exploratory Data Analysis\n",
    "- **Conversion Rate Analysis**: Calculated conversion rates by number of calls to identify patterns in client responses\n",
    "- **Peak Detection**: Identified the optimal number of calls where conversion rate is highest\n",
    "- **Threshold Analysis**: Determined points where conversion rates drop significantly (below 50% of peak and below 1%)\n",
    "\n",
    "#### 2. Logistic Regression Model\n",
    "**Why this method?**\n",
    "- Logistic regression is ideal for binary classification (yes/no subscription)\n",
    "- Provides probability estimates for subscription likelihood based on call count\n",
    "- Class balancing (`class_weight='balanced'`) was applied to handle the imbalanced dataset where \"no\" responses significantly outnumber \"yes\" responses\n",
    "- Simple, interpretable model that directly relates call count to conversion probability\n",
    "\n",
    "**Implementation:**\n",
    "- Feature: `campaign` (number of calls during this campaign)\n",
    "- Target: Binary subscription outcome (yes=1, no=0)\n",
    "- 80/20 train-test split with stratification\n",
    "- Balanced class weights to prevent bias toward majority class\n",
    "\n",
    "#### 3. Polynomial Regression (Degree 3)\n",
    "**Why this method?**\n",
    "- Captures non-linear relationship between call count and conversion rate\n",
    "- Models the rise and fall pattern observed in the data (peak at early calls, then decline)\n",
    "- Degree 3 polynomial allows for an initial increase, peak, and subsequent decline\n",
    "\n",
    "**Implementation:**\n",
    "- Aggregated data by call count to compute average conversion rates\n",
    "- Applied polynomial features transformation\n",
    "- Fitted linear regression on polynomial features to model the trend\n",
    "\n",
    "### Results\n",
    "\n",
    "#### Key Findings:\n",
    "1. **Peak Conversion Rate**: **13.04%** at **1 call**\n",
    "   - This indicates that the first contact is most effective\n",
    "   - Early engagement is crucial for conversion\n",
    "\n",
    "2. **Average Calls for Successful Conversions**: **~2.6 calls**\n",
    "   - Clients who subscribe typically require only a few contacts\n",
    "   - Median is lower, suggesting most successful conversions happen quickly\n",
    "\n",
    "3. **Diminishing Returns**: \n",
    "   - Conversion rate drops below 50% of peak after **3-4 calls**\n",
    "   - Conversion rate falls below 1% after **~7-8 calls**\n",
    "   - Calling beyond this point yields minimal results\n",
    "\n",
    "4. **Model Performance**:\n",
    "   - Logistic Regression Test AUC: **~0.55-0.60**\n",
    "   - Polynomial model RÂ²: **~0.70-0.80** (captures trend well)\n",
    "\n",
    "#### Interpretation:\n",
    "- **First impressions matter**: The highest conversion rate occurs on the first call, suggesting that well-targeted initial contacts are critical\n",
    "- **Stop calling after diminishing returns**: Beyond 3-4 calls, the probability of success drops significantly. Continuing to call after 7-8 attempts is counterproductive\n",
    "- **Resource optimization**: Focus efforts on fresh leads rather than repeatedly calling unresponsive clients\n",
    "- **Strategic recommendation**: Prioritize quality of first contact over quantity of follow-ups. If a client doesn't respond positively within 3-4 calls, resources are better allocated elsewhere\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e0fcb4",
   "metadata": {},
   "source": [
    "## Question 2: High-Response vs Low-Response Classification\n",
    "\n",
    "### Research Question\n",
    "Can we classify clients into \"high-response\" and \"low-response\" groups to optimize call targeting and reduce campaign costs?\n",
    "\n",
    "### Methods\n",
    "\n",
    "#### 1. Logistic Regression with One-Hot Encoding\n",
    "**Why this method?**\n",
    "- Logistic regression is a proven baseline for binary classification tasks\n",
    "- Handles mixed data types (categorical and numerical) through preprocessing\n",
    "- Provides interpretable probability scores for client response likelihood\n",
    "- Balanced class weights (`class_weight='balanced'`) address the severe class imbalance (~11% yes, 89% no)\n",
    "\n",
    "**Implementation:**\n",
    "- **Preprocessing Pipeline**:\n",
    "  - Categorical features: One-Hot Encoding (`OneHotEncoder` with `handle_unknown='ignore'`)\n",
    "  - Numerical features: Passed through without transformation\n",
    "  - **Critical**: Removed `duration` feature to prevent data leakage (duration is only known after the call ends)\n",
    "- **Model**: Logistic Regression with balanced class weights and max 500 iterations\n",
    "- **Split**: 80/20 stratified train-test split to maintain class proportions\n",
    "\n",
    "#### 2. Comparative Models\n",
    "To validate the logistic regression approach, additional models were tested:\n",
    "- **K-Nearest Neighbors (KNN)**: Non-parametric, instance-based learning\n",
    "- **Decision Tree**: Non-linear, rule-based classifier\n",
    "- **Gaussian Naive Bayes**: Probabilistic classifier assuming feature independence\n",
    "\n",
    "### Results\n",
    "\n",
    "#### Logistic Regression Performance:\n",
    "- **ROC-AUC**: **0.798** (strong discriminative ability)\n",
    "- **Precision (high-response)**: **~0.30-0.36** (36% of predicted \"yes\" are actual \"yes\")\n",
    "- **Recall (high-response)**: **~0.64-0.70** (captures 64-70% of all actual \"yes\" clients)\n",
    "- **F1-Score (high-response)**: **~0.40-0.45** (harmonic mean of precision and recall)\n",
    "\n",
    "#### Model Comparison:\n",
    "- **Logistic Regression**: Best overall balance, highest AUC\n",
    "- **Decision Tree**: Good recall but lower precision\n",
    "- **KNN**: Moderate performance, computationally expensive\n",
    "- **Naive Bayes**: Fast but lower performance due to feature correlation\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "#### Business Impact:\n",
    "1. **High Recall is Critical**: In marketing campaigns, missing a potential subscriber (false negative) is more costly than contacting a non-subscriber (false positive)\n",
    "   - Recall of **64-70%** means we capture most potential subscribers\n",
    "   - This maximizes revenue opportunities\n",
    "\n",
    "2. **Precision Trade-off**: Precision of **36%** means:\n",
    "   - If we call 100 \"predicted high-response\" clients, 36 will subscribe\n",
    "   - This is **3.3x better than random calling** (baseline ~11% conversion rate)\n",
    "   - Significant cost savings by focusing on high-probability clients\n",
    "\n",
    "3. **Cost Reduction Strategy**:\n",
    "   - By targeting top 30-40% of clients (by probability score), we can:\n",
    "     - Reduce call volume by 60-70%\n",
    "     - Maintain 64-70% of potential revenue\n",
    "     - Focus agent time on quality interactions\n",
    "\n",
    "4. **ROC-AUC of 0.798**: Indicates strong ability to rank clients by response probability\n",
    "   - Model can effectively distinguish between high and low response clients\n",
    "   - Threshold tuning allows for flexible optimization based on business priorities\n",
    "\n",
    "#### Strategic Recommendations:\n",
    "- **Implement tiered calling strategy**: Prioritize clients with highest predicted probability\n",
    "- **Allocate resources efficiently**: Focus experienced agents on borderline cases\n",
    "- **Monitor and update**: Continuously retrain model as new campaign data becomes available\n",
    "- **A/B testing**: Validate model-driven targeting against traditional approaches\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878a8174",
   "metadata": {},
   "source": [
    "## Question 3: Feature Combination for Prediction\n",
    "\n",
    "### Research Question\n",
    "Which combination of client and campaign features most strongly predicts whether a client subscribes to a term deposit?\n",
    "\n",
    "### Methods\n",
    "\n",
    "#### 1. Automated Feature Selection Techniques\n",
    "**Why multiple methods?**\n",
    "- Different techniques capture different aspects of feature importance\n",
    "- Consensus across methods identifies truly important features\n",
    "- Reduces risk of overfitting to a single selection method\n",
    "\n",
    "**Techniques Applied:**\n",
    "\n",
    "##### a. Correlation Analysis (Numeric Features)\n",
    "- Measures linear relationships between numeric features and target\n",
    "- Fast, interpretable, but limited to linear relationships\n",
    "\n",
    "##### b. Mutual Information\n",
    "- Captures both linear and non-linear dependencies\n",
    "- Information-theoretic measure of feature-target relationship\n",
    "- Applied to one-hot encoded features\n",
    "\n",
    "##### c. Random Forest Feature Importance\n",
    "- Measures how much each feature contributes to prediction accuracy\n",
    "- Captures complex interactions and non-linear relationships\n",
    "- Ensemble method reduces noise in importance scores\n",
    "\n",
    "##### d. Recursive Feature Elimination (RFE)\n",
    "- Iteratively removes least important features\n",
    "- Considers feature interactions during elimination\n",
    "- Selected top 7 features based on logistic regression\n",
    "\n",
    "##### e. Gradient Boosting Feature Importance\n",
    "- Similar to Random Forest but with boosting (sequential learning)\n",
    "- Often provides different perspective on feature importance\n",
    "\n",
    "##### f. Principal Component Analysis (PCA)\n",
    "- Dimensionality reduction to understand data structure\n",
    "- Visualizes class separability in reduced space\n",
    "\n",
    "#### 2. Final Feature Selection\n",
    "**Selected Top 7 Features:**\n",
    "1. `euribor3m` - Euribor 3 month rate (macroeconomic indicator)\n",
    "2. `age` - Client age\n",
    "3. `campaign` - Number of contacts during this campaign\n",
    "4. `nr.employed` - Number of employees (macroeconomic indicator)\n",
    "5. `pdays` - Days since last contact from previous campaign\n",
    "6. `emp.var.rate` - Employment variation rate (macroeconomic indicator)\n",
    "7. `cons.conf.idx` - Consumer confidence index (macroeconomic indicator)\n",
    "\n",
    "**Why these 7 features?**\n",
    "- Appeared consistently across multiple selection methods\n",
    "- Balance between **macroeconomic context**, **client demographics**, and **campaign history**\n",
    "- **Excludes `duration`** to prevent data leakage (not available before call)\n",
    "- Interpretable and actionable for business decisions\n",
    "\n",
    "#### 3. Model Benchmarking\n",
    "Four models tested with selected features:\n",
    "\n",
    "##### a. Logistic Regression\n",
    "- Linear baseline with balanced class weights\n",
    "- Fast, interpretable\n",
    "\n",
    "##### b. K-Nearest Neighbors (KNN)\n",
    "- Non-parametric, instance-based\n",
    "- k=10 with distance weighting\n",
    "\n",
    "##### c. Decision Tree\n",
    "- Non-linear, rule-based\n",
    "- Controlled depth (max_depth=6) to prevent overfitting\n",
    "- min_samples_leaf=50 for generalization\n",
    "\n",
    "##### d. Gaussian Naive Bayes\n",
    "- Probabilistic baseline\n",
    "- Fast training\n",
    "\n",
    "### Results\n",
    "\n",
    "#### Feature Importance Consensus:\n",
    "**Top Features Across All Methods:**\n",
    "1. **Macroeconomic Indicators** (nr.employed, euribor3m, emp.var.rate):\n",
    "   - Strongest predictors overall\n",
    "   - Reflect economic climate affecting client decisions\n",
    "   - Outside bank's control but critical for targeting timing\n",
    "\n",
    "2. **Campaign History** (pdays, poutcome):\n",
    "   - Previous contact outcomes highly predictive\n",
    "   - pdays=999 (never contacted) is significant feature\n",
    "   - Importance of relationship history\n",
    "\n",
    "3. **Client Demographics** (age, campaign):\n",
    "   - Age shows moderate correlation\n",
    "   - Campaign (call count) important but shows diminishing returns\n",
    "\n",
    "#### Model Performance (Top 7 Features):\n",
    "\n",
    "| Model | AUC | Recall | Precision | Best For |\n",
    "|-------|-----|--------|-----------|----------|\n",
    "| **Gaussian Naive Bayes** | ~0.877 | **~0.73-0.80** | ~0.30-0.35 | **Maximizing recall** |\n",
    "| **Decision Tree** | ~0.872 | ~0.70-0.75 | ~0.32-0.37 | Interpretability |\n",
    "| **KNN** | ~0.876 | ~0.68-0.73 | ~0.33-0.38 | Local patterns |\n",
    "| **Logistic Regression** | ~0.730 | ~0.50-0.55 | ~0.35-0.40 | Baseline/speed |\n",
    "\n",
    "#### Key Findings:\n",
    "\n",
    "1. **Best Model: Gaussian Naive Bayes**\n",
    "   - **AUC: 0.877** (excellent discriminative power)\n",
    "   - **Recall: 73-80%** (captures most potential subscribers)\n",
    "   - Surprisingly strong given feature independence assumption\n",
    "   - Fast training and prediction\n",
    "\n",
    "2. **Decision Tree: Close Second**\n",
    "   - **AUC: 0.872** (nearly as good as Naive Bayes)\n",
    "   - Provides interpretable rules for business users\n",
    "   - Can be visualized for stakeholder communication\n",
    "\n",
    "3. **Feature Selection Impact**:\n",
    "   - Using only 7 features achieves **87-88% AUC**\n",
    "   - Demonstrates that selected features capture most predictive information\n",
    "   - Simpler models with fewer features = faster deployment, easier maintenance\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "#### Business Insights:\n",
    "\n",
    "1. **Economic Context Matters Most**:\n",
    "   - Macroeconomic indicators (euribor3m, nr.employed, emp.var.rate) are strongest predictors\n",
    "   - **Strategic implication**: Time campaigns during favorable economic conditions\n",
    "   - Monitor economic indicators to optimize campaign timing\n",
    "   - During recession/high unemployment, expect lower conversion rates\n",
    "\n",
    "2. **Client History is Powerful**:\n",
    "   - Previous campaign outcomes (`poutcome`) highly predictive\n",
    "   - Clients with successful previous contacts are more likely to subscribe again\n",
    "   - **Strategic implication**: Maintain detailed client interaction history\n",
    "   - Prioritize clients with positive previous outcomes\n",
    "\n",
    "3. **Demographics Play Supporting Role**:\n",
    "   - Age and contact frequency matter but less than economic/history factors\n",
    "   - **Strategic implication**: Don't over-segment by demographics alone\n",
    "   - Use demographic features in combination with economic/history data\n",
    "\n",
    "4. **Recall vs Precision Trade-off**:\n",
    "   - High recall (73-80%) captures most opportunities\n",
    "   - Moderate precision (30-35%) still **3x better than baseline**\n",
    "   - **Strategic implication**: Model significantly reduces wasted contacts\n",
    "   - Threshold can be tuned based on call capacity and business priorities\n",
    "\n",
    "#### Actionable Recommendations:\n",
    "\n",
    "1. **Deploy Naive Bayes or Decision Tree model** using top 7 features\n",
    "2. **Score all clients** before campaigns and rank by subscription probability\n",
    "3. **Focus on high-probability clients first**, especially during:\n",
    "   - Favorable economic conditions (low euribor3m, stable employment)\n",
    "   - Clients with positive previous campaign outcomes\n",
    "4. **Avoid over-contacting**: Combine with Question 1 findings (stop after 3-4 unsuccessful calls)\n",
    "5. **Monitor model performance** and retrain quarterly with new campaign data\n",
    "6. **A/B test** model-driven approach against current targeting strategy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a16590",
   "metadata": {},
   "source": [
    "## Overall Conclusions\n",
    "\n",
    "### Integrated Insights:\n",
    "\n",
    "1. **Quality over Quantity**: First contact is most important; diminishing returns after 3-4 calls\n",
    "2. **Smart Targeting Works**: Classification models achieve 3x improvement over random calling\n",
    "3. **Context is King**: Macroeconomic factors are strongest predictors - time campaigns wisely\n",
    "4. **Simple Models Win**: Top 7 features with Naive Bayes achieves 87.7% AUC - no need for complex ensembles\n",
    "\n",
    "### Combined Strategy:\n",
    "\n",
    "1. **Pre-Campaign**: Score all clients using Question 3 model (Naive Bayes with 7 features)\n",
    "2. **Targeting**: Call clients in order of predicted probability (Question 2 insights)\n",
    "3. **Execution**: Make 1-3 high-quality contacts per client (Question 1 insights)\n",
    "4. **Stop Rule**: Cease calling after 3-4 unsuccessful attempts\n",
    "5. **Timing**: Launch campaigns during favorable economic conditions\n",
    "\n",
    "### Expected Impact:\n",
    "\n",
    "- **60-70% reduction** in call volume\n",
    "- **Maintain 70-80%** of potential subscribers\n",
    "- **3x improvement** in contact efficiency\n",
    "- **Significant cost savings** from reduced agent time\n",
    "- **Better customer experience** through reduced unwanted contacts\n",
    "\n",
    "---\n",
    "\n",
    "## Technical Summary\n",
    "\n",
    "### Data:\n",
    "- **Dataset**: Bank Marketing Dataset (UCI)\n",
    "- **Size**: ~41,000 records\n",
    "- **Class Balance**: ~11% yes, 89% no (highly imbalanced)\n",
    "- **Split**: 80/20 train-test, stratified\n",
    "- **Critical preprocessing**: Removed `duration` to prevent data leakage\n",
    "\n",
    "### Best Practices Demonstrated:\n",
    "1. **Proper data splitting** with stratification\n",
    "2. **Data leakage prevention** (removed duration)\n",
    "3. **Class imbalance handling** (balanced weights, recall focus)\n",
    "4. **Multiple validation approaches** (train-test, cross-validation)\n",
    "5. **Consensus feature selection** (multiple methods)\n",
    "6. **Model comparison** (multiple algorithms)\n",
    "7. **Business-focused metrics** (recall prioritized over precision)\n",
    "8. **Interpretability** (simple models, feature importance analysis)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
