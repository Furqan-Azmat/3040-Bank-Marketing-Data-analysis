{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train/Eval split by month (April?June train)\n",
        "Loading the full dataset and creating train/eval pandas DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "data_path = Path('Data/bank-additional-full.csv')\n",
        "df = pd.read_csv(data_path, sep=';')\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_months = {'apr', 'may', 'jun'}\n",
        "mask = df['month'].str.lower().isin(train_months)\n",
        "train_df = df[mask].copy()\n",
        "eval_df = df[~mask].copy()\n",
        "\n",
        "print(f'Train rows: {len(train_df)}  Eval rows: {len(eval_df)}')\n",
        "print('Train y counts:\n', train_df['y'].value_counts())\n",
        "print('Eval y counts:\n', eval_df['y'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Month breakdowns to verify split boundary\n",
        "print('Train months:')\n",
        "display(train_df['month'].value_counts())\n",
        "print('Eval months:')\n",
        "display(eval_df['month'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model: predict high vs low response\n",
        "Using logistic regression with one-hot encoding to classify clients as high-response (`yes`) or low-response (`no`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features/target\n",
        "target_map = {'yes': 1, 'no': 0}\n",
        "y_train = train_df['y'].map(target_map)\n",
        "y_eval = eval_df['y'].map(target_map)\n",
        "\n",
        "X_train = train_df.drop(columns=['y'])\n",
        "X_eval = eval_df.drop(columns=['y'])\n",
        "\n",
        "cat_cols = [c for c in X_train.columns if X_train[c].dtype == 'object']\n",
        "num_cols = [c for c in X_train.columns if X_train[c].dtype != 'object']\n",
        "print(f\"Categorical cols: {len(cat_cols)}  Numeric cols: {len(num_cols)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('categorical', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
        "        ('numeric', 'passthrough', num_cols),\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "clf = Pipeline(steps=[\n",
        "    ('preprocess', preprocess),\n",
        "    ('model', LogisticRegression(max_iter=500, class_weight='balanced', n_jobs=-1)),\n",
        "])\n",
        "clf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "eval_pred = clf.predict(X_eval)\n",
        "eval_proba = clf.predict_proba(X_eval)[:, 1]\n",
        "\n",
        "print(f'Eval ROC-AUC: {roc_auc_score(y_eval, eval_proba):.3f}')\n",
        "print('Classification report (eval):')\n",
        "print(classification_report(y_eval, eval_pred, target_names=['low-response', 'high-response']))\n",
        "\n",
        "cm = pd.DataFrame(\n",
        "    confusion_matrix(y_eval, eval_pred),\n",
        "    index=['true low', 'true high'],\n",
        "    columns=['pred low', 'pred high'],\n",
        ")\n",
        "cm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Score the eval set to prioritize calls\n",
        "scored_eval = eval_df.copy()\n",
        "scored_eval['high_response_score'] = eval_proba\n",
        "scored_eval[['high_response_score', 'y']].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top 5 likely responders\n",
        "scored_eval.sort_values('high_response_score', ascending=False)[['high_response_score', 'y', 'job', 'education', 'contact']].head()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}